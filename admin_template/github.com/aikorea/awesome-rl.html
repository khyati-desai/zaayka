





<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from github.com/aikorea/awesome-rl by HTTrack Website Copier/3.x [XR&CO'2014], Tue, 10 Apr 2018 07:05:01 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
  <link rel="dns-prefetch" href="https://assets-cdn.github.com/">
  <link rel="dns-prefetch" href="https://avatars0.githubusercontent.com/">
  <link rel="dns-prefetch" href="https://avatars1.githubusercontent.com/">
  <link rel="dns-prefetch" href="https://avatars2.githubusercontent.com/">
  <link rel="dns-prefetch" href="https://avatars3.githubusercontent.com/">
  <link rel="dns-prefetch" href="https://github-cloud.s3.amazonaws.com/">
  <link rel="dns-prefetch" href="https://user-images.githubusercontent.com/">



  <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://assets-cdn.github.com/assets/frameworks-8f281eb0a8d2308ceb36e714ba3c3aec.css" />
  <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://assets-cdn.github.com/assets/github-cec46cb7e4a6c4b4c35e2dac77b2196d.css" />
  
  
  <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://assets-cdn.github.com/assets/site-83dc1f7ebc9c7461fe1eab799b56c4c4.css" />
  

  <meta name="viewport" content="width=device-width">
  
  <title>GitHub - aikorea/awesome-rl: Reinforcement learning resources curated</title>
    <meta name="description" content="GitHub is where people build software. More than 27 million people use GitHub to discover, fork, and contribute to over 80 million projects.">
  <link rel="search" type="application/opensearchdescription+xml" href="https://github.com/opensearch.xml" title="GitHub">
  <link rel="fluid-icon" href="https://github.com/fluidicon.png" title="GitHub">
  <meta property="fb:app_id" content="1401488693436528">

    
    <meta property="og:image" content="https://avatars0.githubusercontent.com/u/13035374?s=400&amp;v=4" /><meta property="og:site_name" content="GitHub" /><meta property="og:type" content="object" /><meta property="og:title" content="aikorea/awesome-rl" /><meta property="og:url" content="https://github.com/aikorea/awesome-rl" /><meta property="og:description" content="Reinforcement learning resources curated. Contribute to awesome-rl development by creating an account on GitHub." />

  <link rel="assets" href="https://assets-cdn.github.com/">
  
  <meta name="pjax-timeout" content="1000">
  
  <meta name="request-id" content="2CA1:7FC5:2945BB9:49847E9:5ACB721C" data-pjax-transient>


  

  <meta name="selected-link" value="repo_source" data-pjax-transient>

    <meta name="google-site-verification" content="KT5gs8h0wvaagLKAVWq8bbeNwnZZK1r1XQysX3xurLU">
  <meta name="google-site-verification" content="ZzhVyEFwb7w3e0-uOTltm8Jsck2F5StVihD0exw2fsA">
  <meta name="google-site-verification" content="GXs5KoUUkNCoaAZn7wPN-t01Pywp9M3sEjnt_3_ZWPc">
    <meta name="google-analytics" content="UA-3769691-2">

<meta name="octolytics-host" content="collector.githubapp.com" /><meta name="octolytics-app-id" content="github" /><meta name="octolytics-event-url" content="https://collector.githubapp.com/github-external/browser_event" /><meta name="octolytics-dimension-request_id" content="2CA1:7FC5:2945BB9:49847E9:5ACB721C" /><meta name="octolytics-dimension-region_edge" content="iad" /><meta name="octolytics-dimension-region_render" content="iad" />
<meta name="hydro-events-url" content="https://github.com/hydro_browser_events" />
<meta name="analytics-location" content="/&lt;user-name&gt;/&lt;repo-name&gt;" data-pjax-transient="true" />




  <meta class="js-ga-set" name="dimension1" content="Logged Out">


  

      <meta name="hostname" content="github.com">
    <meta name="user-login" content="">

      <meta name="expected-hostname" content="github.com">
    <meta name="js-proxy-site-detection-payload" content="NDNmNmEwNTgyMjg5ZjhjOTMwMGFjYmRmYmYzNjYyOGMxZmU0YmMzN2E3YjIzNzA1OTcwMDRkODEyMTliMjY5Mnx7InJlbW90ZV9hZGRyZXNzIjoiMjE5LjkxLjIzOS4xMjQiLCJyZXF1ZXN0X2lkIjoiMkNBMTo3RkM1OjI5NDVCQjk6NDk4NDdFOTo1QUNCNzIxQyIsInRpbWVzdGFtcCI6MTUyMzI4MjQ2MSwiaG9zdCI6ImdpdGh1Yi5jb20ifQ==">

    <meta name="enabled-features" content="UNIVERSE_BANNER,FREE_TRIALS,MARKETPLACE_INSIGHTS,MARKETPLACE_SELF_SERVE,MARKETPLACE_INSIGHTS_CONVERSION_PERCENTAGES">

  <meta name="html-safe-nonce" content="c93ed10e39cc785bf529e2db8313369c9d932977">

  <meta http-equiv="x-pjax-version" content="b2b37fc6af759019784f9b02db1e2b01">
  

      <link href="https://github.com/aikorea/awesome-rl/commits/master.atom" rel="alternate" title="Recent Commits to awesome-rl:master" type="application/atom+xml">

  <meta name="description" content="Reinforcement learning resources curated. Contribute to awesome-rl development by creating an account on GitHub.">
  <meta name="go-import" content="github.com/aikorea/awesome-rl git https://github.com/aikorea/awesome-rl.git">

  <meta name="octolytics-dimension-user_id" content="13035374" /><meta name="octolytics-dimension-user_login" content="aikorea" /><meta name="octolytics-dimension-repository_id" content="40465212" /><meta name="octolytics-dimension-repository_nwo" content="aikorea/awesome-rl" /><meta name="octolytics-dimension-repository_public" content="true" /><meta name="octolytics-dimension-repository_is_fork" content="false" /><meta name="octolytics-dimension-repository_network_root_id" content="40465212" /><meta name="octolytics-dimension-repository_network_root_nwo" content="aikorea/awesome-rl" /><meta name="octolytics-dimension-repository_explore_github_marketplace_ci_cta_shown" content="false" />


    <link rel="canonical" href="https://github.com/aikorea/awesome-rl" data-pjax-transient>


  <meta name="browser-stats-url" content="https://api.github.com/_private/browser/stats">

  <meta name="browser-errors-url" content="https://api.github.com/_private/browser/errors">

  <link rel="mask-icon" href="https://assets-cdn.github.com/pinned-octocat.svg" color="#000000">
  <link rel="icon" type="image/x-icon" class="js-site-favicon" href="https://assets-cdn.github.com/favicon.ico">

<meta name="theme-color" content="#1e2327">



<link rel="manifest" href="https://github.com/manifest.json" crossOrigin="use-credentials">

  </head>

  <body class="logged-out env-production">
    

  <div class="position-relative js-header-wrapper ">
    <a href="#start-of-content" tabindex="1" class="px-2 py-4bg-blue text-white show-on-focus js-skip-to-content">Skip to content</a>
    <div id="js-pjax-loader-bar" class="pjax-loader-bar"><div class="progress"></div></div>

    
    
    



        <header class="Header header-logged-out  position-relative f4 py-3" role="banner">
  <div class="container-lg d-flex px-3">
    <div class="d-flex flex-justify-between flex-items-center">
      <a class="header-logo-invertocat my-0" href="https://github.com/" aria-label="Homepage" data-ga-click="(Logged out) Header, go to homepage, icon:logo-wordmark">
        <svg height="32" class="octicon octicon-mark-github" viewBox="0 0 16 16" version="1.1" width="32" aria-hidden="true"><path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z"/></svg>
      </a>

    </div>

    <div class="HeaderMenu HeaderMenu--bright d-flex flex-justify-between flex-auto">
        <nav class="mt-0">
          <ul class="d-flex list-style-none">
              <li class="ml-2">
                <a class="js-selected-navigation-item HeaderNavlink px-0 py-2 m-0" data-ga-click="Header, click, Nav menu - item:features" data-selected-links="/features /features/project-management /features/code-review /features/project-management /features/integrations /features" href="https://github.com/features">
                  Features
</a>              </li>
              <li class="ml-4">
                <a class="js-selected-navigation-item HeaderNavlink px-0 py-2 m-0" data-ga-click="Header, click, Nav menu - item:business" data-selected-links="/business /business/security /business/customers /business" href="https://github.com/business">
                  Business
</a>              </li>

              <li class="ml-4">
                <a class="js-selected-navigation-item HeaderNavlink px-0 py-2 m-0" data-ga-click="Header, click, Nav menu - item:explore" data-selected-links="/explore /trending /trending/developers /integrations /integrations/feature/code /integrations/feature/collaborate /integrations/feature/ship showcases showcases_search showcases_landing /explore" href="https://github.com/explore">
                  Explore
</a>              </li>

              <li class="ml-4">
                    <a class="js-selected-navigation-item HeaderNavlink px-0 py-2 m-0" data-ga-click="Header, click, Nav menu - item:marketplace" data-selected-links=" /marketplace" href="https://github.com/marketplace">
                      Marketplace
</a>              </li>
              <li class="ml-4">
                <a class="js-selected-navigation-item HeaderNavlink px-0 py-2 m-0" data-ga-click="Header, click, Nav menu - item:pricing" data-selected-links="/pricing /pricing/developer /pricing/team /pricing/business-hosted /pricing/business-enterprise /pricing" href="https://github.com/pricing">
                  Pricing
</a>              </li>
          </ul>
        </nav>

      <div class="d-flex">
          <div class="d-lg-flex flex-items-center mr-3">
            <div class="header-search scoped-search site-scoped-search js-site-search" role="search">
  <!-- '"` --><!-- </textarea></xmp> --></option></form><form class="js-site-search-form" data-scoped-search-url="/aikorea/awesome-rl/search" data-unscoped-search-url="/search" action="https://github.com/aikorea/awesome-rl/search" accept-charset="UTF-8" method="get"><input name="utf8" type="hidden" value="&#x2713;" />
    <label class="form-control header-search-wrapper  js-chromeless-input-container">
        <a class="header-search-scope no-underline" href="https://github.com/aikorea/awesome-rl">This repository</a>
      <input type="text"
        class="form-control header-search-input  js-site-search-focus js-site-search-field is-clearable"
        data-hotkey="s,/"
        name="q"
        value=""
        placeholder="Search"
        aria-label="Search this repository"
        data-unscoped-placeholder="Search GitHub"
        data-scoped-placeholder="Search"
        autocapitalize="off"
        >
        <input type="hidden" class="js-site-search-type-field" name="type" >
    </label>
</form></div>

          </div>

        <span class="d-inline-block">
            <div class="HeaderNavlink px-0 py-2 m-0">
              <a class="text-bold text-white no-underline" href="https://github.com/login?return_to=%2Faikorea%2Fawesome-rl" data-ga-click="(Logged out) Header, clicked Sign in, text:sign-in">Sign in</a>
                <span class="text-gray">or</span>
                <a class="text-bold text-white no-underline" href="https://github.com/join?source=header-repo" data-ga-click="(Logged out) Header, clicked Sign up, text:sign-up">Sign up</a>
            </div>
        </span>
      </div>
    </div>
  </div>
</header>

  </div>

  <div id="start-of-content" class="show-on-focus"></div>

    <div id="js-flash-container">
</div>



  <div role="main" class="application-main ">
        <div itemscope itemtype="http://schema.org/SoftwareSourceCode" class="">
    <div id="js-repo-pjax-container" data-pjax-container >
      



  



  <div class="pagehead repohead instapaper_ignore readability-menu experiment-repo-nav  ">
    <div class="repohead-details-container clearfix container">

      <ul class="pagehead-actions">
  <li>
      <a href="https://github.com/login?return_to=%2Faikorea%2Fawesome-rl"
    class="btn btn-sm btn-with-count tooltipped tooltipped-n"
    aria-label="You must be signed in to watch a repository" rel="nofollow">
    <svg class="octicon octicon-eye" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8.06 2C3 2 0 8 0 8s3 6 8.06 6C13 14 16 8 16 8s-3-6-7.94-6zM8 12c-2.2 0-4-1.78-4-4 0-2.2 1.8-4 4-4 2.22 0 4 1.8 4 4 0 2.22-1.78 4-4 4zm2-4c0 1.11-.89 2-2 2-1.11 0-2-.89-2-2 0-1.11.89-2 2-2 1.11 0 2 .89 2 2z"/></svg>
    Watch
  </a>
  <a class="social-count" href="https://github.com/aikorea/awesome-rl/watchers"
     aria-label="341 users are watching this repository">
    341
  </a>

  </li>

  <li>
      <a href="https://github.com/login?return_to=%2Faikorea%2Fawesome-rl"
    class="btn btn-sm btn-with-count tooltipped tooltipped-n"
    aria-label="You must be signed in to star a repository" rel="nofollow">
    <svg class="octicon octicon-star" viewBox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M14 6l-4.9-.64L7 1 4.9 5.36 0 6l3.6 3.26L2.67 14 7 11.67 11.33 14l-.93-4.74z"/></svg>
    Star
  </a>

    <a class="social-count js-social-count" href="https://github.com/aikorea/awesome-rl/stargazers"
      aria-label="3518 users starred this repository">
      3,518
    </a>

  </li>

  <li>
      <a href="https://github.com/login?return_to=%2Faikorea%2Fawesome-rl"
        class="btn btn-sm btn-with-count tooltipped tooltipped-n"
        aria-label="You must be signed in to fork a repository" rel="nofollow">
        <svg class="octicon octicon-repo-forked" viewBox="0 0 10 16" version="1.1" width="10" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1a1.993 1.993 0 0 0-1 3.72V6L5 8 3 6V4.72A1.993 1.993 0 0 0 2 1a1.993 1.993 0 0 0-1 3.72V6.5l3 3v1.78A1.993 1.993 0 0 0 5 15a1.993 1.993 0 0 0 1-3.72V9.5l3-3V4.72A1.993 1.993 0 0 0 8 1zM2 4.2C1.34 4.2.8 3.65.8 3c0-.65.55-1.2 1.2-1.2.65 0 1.2.55 1.2 1.2 0 .65-.55 1.2-1.2 1.2zm3 10c-.66 0-1.2-.55-1.2-1.2 0-.65.55-1.2 1.2-1.2.65 0 1.2.55 1.2 1.2 0 .65-.55 1.2-1.2 1.2zm3-10c-.66 0-1.2-.55-1.2-1.2 0-.65.55-1.2 1.2-1.2.65 0 1.2.55 1.2 1.2 0 .65-.55 1.2-1.2 1.2z"/></svg>
        Fork
      </a>

    <a href="https://github.com/aikorea/awesome-rl/network" class="social-count"
       aria-label="844 users forked this repository">
      844
    </a>
  </li>
</ul>

      <h1 class="public ">
  <svg class="octicon octicon-repo" viewBox="0 0 12 16" version="1.1" width="12" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9H3V8h1v1zm0-3H3v1h1V6zm0-2H3v1h1V4zm0-2H3v1h1V2zm8-1v12c0 .55-.45 1-1 1H6v2l-1.5-1.5L3 16v-2H1c-.55 0-1-.45-1-1V1c0-.55.45-1 1-1h10c.55 0 1 .45 1 1zm-1 10H1v2h2v-1h3v1h5v-2zm0-10H2v9h9V1z"/></svg>
  <span class="author" itemprop="author"><a class="url fn" rel="author" href="https://github.com/aikorea">aikorea</a></span><!--
--><span class="path-divider">/</span><!--
--><strong itemprop="name"><a data-pjax="#js-repo-pjax-container" href="https://github.com/aikorea/awesome-rl">awesome-rl</a></strong>

</h1>

    </div>
    
<nav class="reponav js-repo-nav js-sidenav-container-pjax container"
     itemscope
     itemtype="http://schema.org/BreadcrumbList"
     role="navigation"
     data-pjax="#js-repo-pjax-container">

  <span itemscope itemtype="http://schema.org/ListItem" itemprop="itemListElement">
    <a class="js-selected-navigation-item selected reponav-item" itemprop="url" data-hotkey="g c" data-selected-links="repo_source repo_downloads repo_commits repo_releases repo_tags repo_branches repo_packages /aikorea/awesome-rl" href="https://github.com/aikorea/awesome-rl">
      <svg class="octicon octicon-code" viewBox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M9.5 3L8 4.5 11.5 8 8 11.5 9.5 13 14 8 9.5 3zm-5 0L0 8l4.5 5L6 11.5 2.5 8 6 4.5 4.5 3z"/></svg>
      <span itemprop="name">Code</span>
      <meta itemprop="position" content="1">
</a>  </span>

    <span itemscope itemtype="http://schema.org/ListItem" itemprop="itemListElement">
      <a itemprop="url" data-hotkey="g i" class="js-selected-navigation-item reponav-item" data-selected-links="repo_issues repo_labels repo_milestones /aikorea/awesome-rl/issues" href="https://github.com/aikorea/awesome-rl/issues">
        <svg class="octicon octicon-issue-opened" viewBox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg>
        <span itemprop="name">Issues</span>
        <span class="Counter">1</span>
        <meta itemprop="position" content="2">
</a>    </span>

  <span itemscope itemtype="http://schema.org/ListItem" itemprop="itemListElement">
    <a data-hotkey="g p" itemprop="url" class="js-selected-navigation-item reponav-item" data-selected-links="repo_pulls checks /aikorea/awesome-rl/pulls" href="https://github.com/aikorea/awesome-rl/pulls">
      <svg class="octicon octicon-git-pull-request" viewBox="0 0 12 16" version="1.1" width="12" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M11 11.28V5c-.03-.78-.34-1.47-.94-2.06C9.46 2.35 8.78 2.03 8 2H7V0L4 3l3 3V4h1c.27.02.48.11.69.31.21.2.3.42.31.69v6.28A1.993 1.993 0 0 0 10 15a1.993 1.993 0 0 0 1-3.72zm-1 2.92c-.66 0-1.2-.55-1.2-1.2 0-.65.55-1.2 1.2-1.2.65 0 1.2.55 1.2 1.2 0 .65-.55 1.2-1.2 1.2zM4 3c0-1.11-.89-2-2-2a1.993 1.993 0 0 0-1 3.72v6.56A1.993 1.993 0 0 0 2 15a1.993 1.993 0 0 0 1-3.72V4.72c.59-.34 1-.98 1-1.72zm-.8 10c0 .66-.55 1.2-1.2 1.2-.65 0-1.2-.55-1.2-1.2 0-.65.55-1.2 1.2-1.2.65 0 1.2.55 1.2 1.2zM2 4.2C1.34 4.2.8 3.65.8 3c0-.65.55-1.2 1.2-1.2.65 0 1.2.55 1.2 1.2 0 .65-.55 1.2-1.2 1.2z"/></svg>
      <span itemprop="name">Pull requests</span>
      <span class="Counter">9</span>
      <meta itemprop="position" content="3">
</a>  </span>

    <a data-hotkey="g b" class="js-selected-navigation-item reponav-item" data-selected-links="repo_projects new_repo_project repo_project /aikorea/awesome-rl/projects" href="https://github.com/aikorea/awesome-rl/projects">
      <svg class="octicon octicon-project" viewBox="0 0 15 16" version="1.1" width="15" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M10 12h3V2h-3v10zm-4-2h3V2H6v8zm-4 4h3V2H2v12zm-1 1h13V1H1v14zM14 0H1a1 1 0 0 0-1 1v14a1 1 0 0 0 1 1h13a1 1 0 0 0 1-1V1a1 1 0 0 0-1-1z"/></svg>
      Projects
      <span class="Counter" >0</span>
</a>
    <a class="js-selected-navigation-item reponav-item" data-hotkey="g w" data-selected-links="repo_wiki /aikorea/awesome-rl/wiki" href="https://github.com/aikorea/awesome-rl/wiki">
      <svg class="octicon octicon-book" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M3 5h4v1H3V5zm0 3h4V7H3v1zm0 2h4V9H3v1zm11-5h-4v1h4V5zm0 2h-4v1h4V7zm0 2h-4v1h4V9zm2-6v9c0 .55-.45 1-1 1H9.5l-1 1-1-1H2c-.55 0-1-.45-1-1V3c0-.55.45-1 1-1h5.5l1 1 1-1H15c.55 0 1 .45 1 1zm-8 .5L7.5 3H2v9h6V3.5zm7-.5H9.5l-.5.5V12h6V3z"/></svg>
      Wiki
</a>

  <a class="js-selected-navigation-item reponav-item" data-selected-links="repo_graphs repo_contributors dependency_graph pulse /aikorea/awesome-rl/pulse" href="https://github.com/aikorea/awesome-rl/pulse">
    <svg class="octicon octicon-graph" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M16 14v1H0V0h1v14h15zM5 13H3V8h2v5zm4 0H7V3h2v10zm4 0h-2V6h2v7z"/></svg>
    Insights
</a>

</nav>


  </div>

<div class="container new-discussion-timeline experiment-repo-nav  ">
  <div class="repository-content ">

    
      <div class="signup-prompt-bg rounded-1">
      <div class="signup-prompt p-4 text-center mb-4 rounded-1">
        <div class="position-relative">
          <!-- '"` --><!-- </textarea></xmp> --></option></form><form action="https://github.com/site/dismiss_signup_prompt" accept-charset="UTF-8" method="post"><input name="utf8" type="hidden" value="&#x2713;" /><input type="hidden" name="authenticity_token" value="ioSjxRu9KzHSPwSXyRVC3RIMuraii7J7Xsx3MsYYIFto/1+WnEVJcXhrbJWNden8Wkty2CQKczPm0g/PgO0mDw==" />
            <button type="submit" class="position-absolute top-0 right-0 btn-link link-gray" data-ga-click="(Logged out) Sign up prompt, clicked Dismiss, text:dismiss">
              Dismiss
            </button>
</form>
          <h3 class="pt-2">Join GitHub today</h3>
          <p class="col-6 mx-auto">GitHub is home to over 20 million developers working together to host and review code, manage projects, and build software together.</p>
          <p class="pb-2">
            <a class="btn btn-blue" href="https://github.com/join?source=prompt-code" data-ga-click="(Logged out) Sign up prompt, clicked Sign up, text:sign-up">Sign up</a>
          </p>
        </div>
      </div>
    </div>


  <div class="js-repo-meta-container">
  <div class="repository-meta mb-0 mb-3 js-repo-meta-edit js-details-container ">
    <div class="repository-meta-content col-11 mb-1">
          <span class="col-11 text-gray-dark mr-2" itemprop="about">
            Reinforcement learning resources curated
          </span>
          <span itemprop="url"><a rel="nofollow" href="http://aikorea.org/awesome-rl">http://aikorea.org/awesome-rl</a></span>
    </div>

  </div>

</div>



  <div class="overall-summary ">
    <div class="stats-switcher-viewport js-stats-switcher-viewport">
      <div class="stats-switcher-wrapper">
      <ul class="numbers-summary">
        <li class="commits">
          <a data-pjax href="https://github.com/aikorea/awesome-rl/commits/master">
              <svg class="octicon octicon-history" viewBox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 13H6V6h5v2H8v5zM7 1C4.81 1 2.87 2.02 1.59 3.59L0 2v4h4L2.5 4.5C3.55 3.17 5.17 2.3 7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-.34.03-.67.09-1H.08C.03 7.33 0 7.66 0 8c0 3.86 3.14 7 7 7s7-3.14 7-7-3.14-7-7-7z"/></svg>
              <span class="num text-emphasized">
                129
              </span>
              commits
          </a>
        </li>
        <li>
          <a data-pjax href="https://github.com/aikorea/awesome-rl/branches">
            <svg class="octicon octicon-git-branch" viewBox="0 0 10 16" version="1.1" width="10" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M10 5c0-1.11-.89-2-2-2a1.993 1.993 0 0 0-1 3.72v.3c-.02.52-.23.98-.63 1.38-.4.4-.86.61-1.38.63-.83.02-1.48.16-2 .45V4.72a1.993 1.993 0 0 0-1-3.72C.88 1 0 1.89 0 3a2 2 0 0 0 1 1.72v6.56c-.59.35-1 .99-1 1.72 0 1.11.89 2 2 2 1.11 0 2-.89 2-2 0-.53-.2-1-.53-1.36.09-.06.48-.41.59-.47.25-.11.56-.17.94-.17 1.05-.05 1.95-.45 2.75-1.25S8.95 7.77 9 6.73h-.02C9.59 6.37 10 5.73 10 5zM2 1.8c.66 0 1.2.55 1.2 1.2 0 .65-.55 1.2-1.2 1.2C1.35 4.2.8 3.65.8 3c0-.65.55-1.2 1.2-1.2zm0 12.41c-.66 0-1.2-.55-1.2-1.2 0-.65.55-1.2 1.2-1.2.65 0 1.2.55 1.2 1.2 0 .65-.55 1.2-1.2 1.2zm6-8c-.66 0-1.2-.55-1.2-1.2 0-.65.55-1.2 1.2-1.2.65 0 1.2.55 1.2 1.2 0 .65-.55 1.2-1.2 1.2z"/></svg>
            <span class="num text-emphasized">
              2
            </span>
            branches
          </a>
        </li>

        <li>
          <a href="https://github.com/aikorea/awesome-rl/releases">
            <svg class="octicon octicon-tag" viewBox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.73 1.73C7.26 1.26 6.62 1 5.96 1H3.5C2.13 1 1 2.13 1 3.5v2.47c0 .66.27 1.3.73 1.77l6.06 6.06c.39.39 1.02.39 1.41 0l4.59-4.59a.996.996 0 0 0 0-1.41L7.73 1.73zM2.38 7.09c-.31-.3-.47-.7-.47-1.13V3.5c0-.88.72-1.59 1.59-1.59h2.47c.42 0 .83.16 1.13.47l6.14 6.13-4.73 4.73-6.13-6.15zM3.01 3h2v2H3V3h.01z"/></svg>
            <span class="num text-emphasized">
              0
            </span>
            releases
          </a>
        </li>

        <li>
            <a href="https://github.com/aikorea/awesome-rl/graphs/contributors">
  <svg class="octicon octicon-organization" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M16 12.999c0 .439-.45 1-1 1H7.995c-.539 0-.994-.447-.995-.999H1c-.54 0-1-.561-1-1 0-2.634 3-4 3-4s.229-.409 0-1c-.841-.621-1.058-.59-1-3 .058-2.419 1.367-3 2.5-3s2.442.58 2.5 3c.058 2.41-.159 2.379-1 3-.229.59 0 1 0 1s1.549.711 2.42 2.088C9.196 9.369 10 8.999 10 8.999s.229-.409 0-1c-.841-.62-1.058-.59-1-3 .058-2.419 1.367-3 2.5-3s2.437.581 2.495 3c.059 2.41-.158 2.38-1 3-.229.59 0 1 0 1s3.005 1.366 3.005 4"/></svg>
    <span class="num text-emphasized">
      31
    </span>
    contributors
</a>

        </li>
      </ul>

      </div>
    </div>
  </div>




  <div class="file-navigation in-mid-page">

    <details class="get-repo-select-menu js-get-repo-select-menu float-right position-relative dropdown-details details-reset">
  <summary class="btn btn-sm btn-primary">
    Clone or download
    <span class="dropdown-caret"></span>
  </summary>
  <div class="position-relative">
    <div class="get-repo-modal dropdown-menu dropdown-menu-sw pb-0 js-toggler-container  js-get-repo-modal">

      <div class="get-repo-modal-options">
          <div class="clone-options https-clone-options">

            <h4 class="mb-1">
              Clone with HTTPS
              <a class="muted-link" href="https://help.github.com/articles/which-remote-url-should-i-use" target="_blank" title="Which remote URL should I use?">
                <svg class="octicon octicon-question" viewBox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M6 10h2v2H6v-2zm4-3.5C10 8.64 8 9 8 9H6c0-.55.45-1 1-1h.5c.28 0 .5-.22.5-.5v-1c0-.28-.22-.5-.5-.5h-1c-.28 0-.5.22-.5.5V7H4c0-1.5 1.5-3 3-3s3 1 3 2.5zM7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7z"/></svg>
              </a>
            </h4>
            <p class="mb-2 get-repo-decription-text">
              Use Git or checkout with SVN using the web URL.
            </p>

            <div class="input-group">
  <input type="text" class="form-control input-monospace input-sm js-url-field" value="https://github.com/aikorea/awesome-rl.git" aria-label="Clone this repository at https://github.com/aikorea/awesome-rl.git" readonly>
  <div class="input-group-button">
    <clipboard-copy
        value="https://github.com/aikorea/awesome-rl.git"
        aria-label="Copy to clipboard"
        class="btn btn-sm tooltipped tooltipped-s"
        copied-label="Copied!">
      <svg class="octicon octicon-clippy" viewBox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M2 13h4v1H2v-1zm5-6H2v1h5V7zm2 3V8l-3 3 3 3v-2h5v-2H9zM4.5 9H2v1h2.5V9zM2 12h2.5v-1H2v1zm9 1h1v2c-.02.28-.11.52-.3.7-.19.18-.42.28-.7.3H1c-.55 0-1-.45-1-1V4c0-.55.45-1 1-1h3c0-1.11.89-2 2-2 1.11 0 2 .89 2 2h3c.55 0 1 .45 1 1v5h-1V6H1v9h10v-2zM2 5h8c0-.55-.45-1-1-1H8c-.55 0-1-.45-1-1s-.45-1-1-1-1 .45-1 1-.45 1-1 1H3c-.55 0-1 .45-1 1z"/></svg>
    </clipboard-copy>
  </div>
</div>

          </div>

        <div class="mt-2">
          
<a href="https://github.com/aikorea/awesome-rl/archive/master.zip"
   class="btn btn-outline get-repo-btn
"
   rel="nofollow"
   data-ga-click="Repository, download zip, location:repo overview">
  Download ZIP
</a>

        </div>
      </div>

      <div class="js-modal-download-mac py-2 px-3 d-none">
        <h4 class="lh-condensed mb-3">Launching GitHub Desktop<span class="animated-ellipsis-container"><span class="animated-ellipsis">...</span></span></h4>
        <p class="text-gray">If nothing happens, <a href="https://desktop.github.com/">download GitHub Desktop</a> and try again.</p>
        <p><button class="btn-link js-get-repo-modal-download-back">Go back</button></p>
      </div>

      <div class="js-modal-download-windows py-2 px-3 d-none">
        <h4 class="lh-condensed mb-3">Launching GitHub Desktop<span class="animated-ellipsis-container"><span class="animated-ellipsis">...</span></span></h4>
        <p class="text-gray">If nothing happens, <a href="https://desktop.github.com/">download GitHub Desktop</a> and try again.</p>
        <p><button class="btn-link js-get-repo-modal-download-back">Go back</button></p>
      </div>

      <div class="js-modal-download-xcode py-2 px-3 d-none">
        <h4 class="lh-condensed mb-3">Launching Xcode<span class="animated-ellipsis-container"><span class="animated-ellipsis">...</span></span></h4>
        <p class="text-gray">If nothing happens, <a href="https://developer.apple.com/xcode/">download Xcode</a> and try again.</p>
        <p><button class="btn-link js-get-repo-modal-download-back">Go back</button></p>
      </div>

      <div class="js-modal-download-visual-studio py-2 px-3 d-none">
        <h4 class="lh-condensed mb-3">Launching Visual Studio<span class="animated-ellipsis-container"><span class="animated-ellipsis">...</span></span></h4>
        <p class="text-gray">If nothing happens, <a href="https://visualstudio.github.com/">download the GitHub extension for Visual Studio</a> and try again.</p>
        <p><button class="btn-link js-get-repo-modal-download-back">Go back</button></p>
      </div>

    </div>
  </div>
</details>


  <div class="BtnGroup float-right">

    <a href="https://github.com/aikorea/awesome-rl/find/master"
      class="btn btn-sm empty-icon float-right BtnGroup-item"
      data-pjax
      data-hotkey="t"
      data-ga-click="Repository, find file, location:repo overview">
      Find file
    </a>
  </div>

  
<div class="select-menu branch-select-menu js-menu-container js-select-menu float-left">
  <button class=" btn btn-sm select-menu-button js-menu-target css-truncate" data-hotkey="w"
    
    type="button" aria-label="Switch branches or tags" aria-expanded="false" aria-haspopup="true">
      <i>Branch:</i>
      <span class="js-select-button css-truncate-target">master</span>
  </button>

  <div class="select-menu-modal-holder js-menu-content js-navigation-container" data-pjax>

    <div class="select-menu-modal">
      <div class="select-menu-header">
        <svg class="octicon octicon-x js-menu-close" role="img" aria-label="Close" viewBox="0 0 12 16" version="1.1" width="12" height="16"><path fill-rule="evenodd" d="M7.48 8l3.75 3.75-1.48 1.48L6 9.48l-3.75 3.75-1.48-1.48L4.52 8 .77 4.25l1.48-1.48L6 6.52l3.75-3.75 1.48 1.48z"/></svg>
        <span class="select-menu-title">Switch branches/tags</span>
      </div>

      <div class="select-menu-filters">
        <div class="select-menu-text-filter">
          <input type="text" aria-label="Filter branches/tags" id="context-commitish-filter-field" class="form-control js-filterable-field js-navigation-enable" placeholder="Filter branches/tags">
        </div>
        <div class="select-menu-tabs">
          <ul>
            <li class="select-menu-tab">
              <a href="#" data-tab-filter="branches" data-filter-placeholder="Filter branches/tags" class="js-select-menu-tab" role="tab">Branches</a>
            </li>
            <li class="select-menu-tab">
              <a href="#" data-tab-filter="tags" data-filter-placeholder="Find a tag…" class="js-select-menu-tab" role="tab">Tags</a>
            </li>
          </ul>
        </div>
      </div>

      <div class="select-menu-list select-menu-tab-bucket js-select-menu-tab-bucket" data-tab-filter="branches" role="menu">

        <div data-filterable-for="context-commitish-filter-field" data-filterable-type="substring">


            <a class="select-menu-item js-navigation-item js-navigation-open "
               href="https://github.com/aikorea/awesome-rl/tree/gh-pages"
               data-name="gh-pages"
               data-skip-pjax="true"
               rel="nofollow">
              <svg class="octicon octicon-check select-menu-item-icon" viewBox="0 0 12 16" version="1.1" width="12" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M12 5l-8 8-4-4 1.5-1.5L4 10l6.5-6.5z"/></svg>
              <span class="select-menu-item-text css-truncate-target js-select-menu-filter-text">
                gh-pages
              </span>
            </a>
            <a class="select-menu-item js-navigation-item js-navigation-open selected"
               href="https://github.com/aikorea/awesome-rl/tree/master"
               data-name="master"
               data-skip-pjax="true"
               rel="nofollow">
              <svg class="octicon octicon-check select-menu-item-icon" viewBox="0 0 12 16" version="1.1" width="12" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M12 5l-8 8-4-4 1.5-1.5L4 10l6.5-6.5z"/></svg>
              <span class="select-menu-item-text css-truncate-target js-select-menu-filter-text">
                master
              </span>
            </a>
        </div>

          <div class="select-menu-no-results">Nothing to show</div>
      </div>

      <div class="select-menu-list select-menu-tab-bucket js-select-menu-tab-bucket" data-tab-filter="tags">
        <div data-filterable-for="context-commitish-filter-field" data-filterable-type="substring">


        </div>

        <div class="select-menu-no-results">Nothing to show</div>
      </div>

    </div>
  </div>
</div>


        <button type="button" class="btn btn-sm disabled tooltipped tooltipped-n new-pull-request-btn" aria-label="You must be signed in to create a pull request">
          New pull request
        </button>

  <div class="breadcrumb">
    
  </div>
</div>


  


  <div class="commit-tease js-details-container Details">
    <span class="float-right">
      Latest commit
      <a class="commit-tease-sha" href="https://github.com/aikorea/awesome-rl/commit/9defc2644af26888ddf799a8340f748b5f0b85cc" data-pjax>
        9defc26
      </a>
      <span itemprop="dateModified"><relative-time datetime="2018-01-08T02:24:30Z">Jan 8, 2018</relative-time></span>
    </span>


      <div class="d-flex no-wrap">
        
<div class="AvatarStack flex-self-start ">
  <div class="AvatarStack-body tooltipped tooltipped-se tooltipped-align-left-1"
       aria-label="hshyunsookim">

        <a href="https://github.com/hshyunsookim" data-skip-pjax="true" class="avatar">
          <img src="https://avatars3.githubusercontent.com/u/10506375?s=40&amp;v=4" width="20" height="20" alt="@hshyunsookim">
        </a>
  </div>
</div>

        <div class="flex-auto f6">
          
      <a href="https://github.com/aikorea/awesome-rl/commits?author=hshyunsookim"
     class="commit-author tooltipped tooltipped-s user-mention"
     aria-label="View all commits by hshyunsookim">hshyunsookim</a>


  committed
  <relative-time datetime="2018-01-08T02:24:30Z">Jan 8, 2018</relative-time>



      <a href="https://github.com/aikorea/awesome-rl/commit/9defc2644af26888ddf799a8340f748b5f0b85cc" class="message" data-pjax="true" title="Edit repo title format">Edit repo title format</a>


        </div>
      </div>
  </div>



<div class="file-wrap">

  <a class="d-none js-permalink-shortcut" data-hotkey="y" href="https://github.com/aikorea/awesome-rl/tree/9defc2644af26888ddf799a8340f748b5f0b85cc">Permalink</a>

  <table class="files js-navigation-container js-active-navigation-container" data-pjax>


    <tbody>
      <tr class="warning include-fragment-error">
        <td class="icon"><svg class="octicon octicon-alert" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8.865 1.52c-.18-.31-.51-.5-.87-.5s-.69.19-.87.5L.275 13.5c-.18.31-.18.69 0 1 .19.31.52.5.87.5h13.7c.36 0 .69-.19.86-.5.17-.31.18-.69.01-1L8.865 1.52zM8.995 13h-2v-2h2v2zm0-3h-2V6h2v4z"/></svg></td>
        <td class="content" colspan="3">Failed to load latest commit information.</td>
      </tr>

        <tr class="js-navigation-item">
          <td class="icon">
            <svg class="octicon octicon-file" viewBox="0 0 12 16" version="1.1" width="12" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M6 5H2V4h4v1zM2 8h7V7H2v1zm0 2h7V9H2v1zm0 2h7v-1H2v1zm10-7.5V14c0 .55-.45 1-1 1H1c-.55 0-1-.45-1-1V2c0-.55.45-1 1-1h7.5L12 4.5zM11 5L8 2H1v12h10V5z"/></svg>
            <img width="16" height="16" class="spinner" alt="" src="https://assets-cdn.github.com/images/spinners/octocat-spinner-32.gif" />
          </td>
          <td class="content">
            <span class="css-truncate css-truncate-target"><a class="js-navigation-open" title="README.md" id="04c6e90faac2675aa89e2176d2eec7d8-9a9d68a8994550f87bdcf85d6ab8b343184fd803" href="https://github.com/aikorea/awesome-rl/blob/master/README.md">README.md</a></span>
          </td>
          <td class="message">
            <span class="css-truncate css-truncate-target">
                  <a data-pjax="true" title="Edit repo title format" class="message" href="https://github.com/aikorea/awesome-rl/commit/9defc2644af26888ddf799a8340f748b5f0b85cc">Edit repo title format</a>
            </span>
          </td>
          <td class="age">
            <span class="css-truncate css-truncate-target"><time-ago datetime="2018-01-08T02:24:30Z">Jan 8, 2018</time-ago></span>
          </td>
        </tr>
    </tbody>
  </table>

</div>



  <div id="readme" class="readme boxed-group clearfix announce instapaper_body md">
    <h3>
      <svg class="octicon octicon-book" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M3 5h4v1H3V5zm0 3h4V7H3v1zm0 2h4V9H3v1zm11-5h-4v1h4V5zm0 2h-4v1h4V7zm0 2h-4v1h4V9zm2-6v9c0 .55-.45 1-1 1H9.5l-1 1-1-1H2c-.55 0-1-.45-1-1V3c0-.55.45-1 1-1h5.5l1 1 1-1H15c.55 0 1 .45 1 1zm-8 .5L7.5 3H2v9h6V3.5zm7-.5H9.5l-.5.5V12h6V3z"/></svg>
      README.md
    </h3>

      <article class="markdown-body entry-content" itemprop="text"><h1><a href="#awesome-reinforcement-learning--" aria-hidden="true" class="anchor" id="user-content-awesome-reinforcement-learning--"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Awesome Reinforcement Learning  <a href="https://github.com/sindresorhus/awesome"><img src="https://camo.githubusercontent.com/13c4e50d88df7178ae1882a203ed57b641674f94/68747470733a2f2f63646e2e7261776769742e636f6d2f73696e647265736f726875732f617765736f6d652f643733303566333864323966656437386661383536353265336136336531353464643865383832392f6d656469612f62616467652e737667" alt="Awesome" data-canonical-src="https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg" style="max-width:100%;"></a></h1>
<p>A curated list of resources dedicated to reinforcement learning.</p>
<p>We have pages for other topics: <a href="https://github.com/kjw0612/awesome-rnn">awesome-rnn</a>, <a href="https://github.com/kjw0612/awesome-deep-vision">awesome-deep-vision</a>, <a href="https://github.com/kjw0612/awesome-random-forest">awesome-random-forest</a></p>
<p>Maintainers: <a href="http://sites.duke.edu/hyunsookim/" rel="nofollow">Hyunsoo Kim</a>, <a href="http://github.com/kjw0612">Jiwon Kim</a></p>
<p>We are looking for more contributors and maintainers!</p>
<h2><a href="#contributing" aria-hidden="true" class="anchor" id="user-content-contributing"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Contributing</h2>
<p>Please feel free to <a href="https://github.com/aikorea/awesome-rl/pulls">pull requests</a></p>
<h2><a href="#table-of-contents" aria-hidden="true" class="anchor" id="user-content-table-of-contents"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Table of Contents</h2>
<ul>
<li><a href="#codes">Codes</a></li>
<li><a href="#theory">Theory</a>
<ul>
<li><a href="#lectures">Lectures</a></li>
<li><a href="#books">Books</a></li>
<li><a href="#surveys">Surveys</a></li>
<li><a href="#papers--thesis">Papers / Thesis</a></li>
</ul>
</li>
<li><a href="#applications">Applications</a>
<ul>
<li><a href="#game-playing">Game Playing</a></li>
<li><a href="#robotics">Robotics</a></li>
<li><a href="#control">Control</a></li>
<li><a href="#operations-research">Operations Research</a></li>
<li><a href="#human-computer-interaction">Human Computer Interaction</a></li>
</ul>
</li>
<li><a href="#tutorials--websites">Tutorials / Websites</a></li>
<li><a href="#online-demos">Online Demos</a></li>
<li><a href="#open-source-reinforcement-learning-platforms">Open Source Reinforcement Learning Platforms</a></li>
</ul>
<h2><a href="#codes" aria-hidden="true" class="anchor" id="user-content-codes"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Codes</h2>
<ul>
<li>Codes for examples and exercises in Richard Sutton and Andrew Barto's Reinforcement Learning: An Introduction</li>
<li><a href="https://github.com/ShangtongZhang/reinforcement-learning-an-introduction">Python Code</a></li>
<li><a href="http://waxworksmath.com/Authors/N_Z/Sutton/sutton.html" rel="nofollow">MATLAB Code</a></li>
<li><a href="https://webdocs.cs.ualberta.ca/~sutton/book/code/code.html" rel="nofollow">C/Lisp Code</a></li>
<li><a href="http://webdocs.cs.ualberta.ca/~sutton/book/ebook/the-book.html" rel="nofollow">Book</a></li>
<li>Simulation code for Reinforcement Learning Control Problems</li>
<li><a href="http://pages.cs.wisc.edu/~finton/poledriver.html" rel="nofollow">Pole-Cart Problem</a></li>
<li><a href="http://pages.cs.wisc.edu/~finton/qcontroller.html" rel="nofollow">Q-learning Controller</a></li>
<li><a href="http://www.cs.colostate.edu/~anderson/res/rl/matlabpaper/rl.html" rel="nofollow">MATLAB Environment and GUI for Reinforcement Learning</a></li>
<li><a href="http://www-anw.cs.umass.edu/rlr/" rel="nofollow">Reinforcement Learning Repository - University of Massachusetts, Amherst</a></li>
<li><a href="http://burlap.cs.brown.edu/" rel="nofollow">Brown-UMBC Reinforcement Learning and Planning Library (Java)</a></li>
<li><a href="http://www.moneyscience.com/pg/blog/StatAlgo/read/635759/reinforcement-learning-in-r-markov-decision-process-mdp-and-value-iteration" rel="nofollow">Reinforcement Learning in R (MDP, Value Iteration)</a></li>
<li><a href="https://jamh-web.appspot.com/download.htm" rel="nofollow">Reinforcement Learning Environment in Python and MATLAB</a></li>
<li><a href="http://glue.rl-community.org/wiki/Main_Page" rel="nofollow">RL-Glue</a> (standard interface for RL) and <a href="http://library.rl-community.org/wiki/Main_Page" rel="nofollow">RL-Glue Library</a></li>
<li><a href="http://www.pybrain.org/" rel="nofollow">PyBrain Library</a> - Python-Based Reinforcement learning, Artificial intelligence, and Neural network</li>
<li><a href="http://rlpy.readthedocs.org/en/latest/" rel="nofollow">RLPy Framework</a> -  Value-Function-Based Reinforcement Learning Framework for Education and Research</li>
<li><a href="http://mmlf.sourceforge.net/" rel="nofollow">Maja</a> - Machine learning framework for problems in Reinforcement Learning in python</li>
<li><a href="http://servicerobotik.hs-weingarten.de/en/teachingbox.php" rel="nofollow">TeachingBox</a> - Java based Reinforcement Learning framework</li>
<li><a href="http://www.ias.informatik.tu-darmstadt.de/Research/PolicyGradientToolbox" rel="nofollow">Policy Gradient Reinforcement Learning Toolbox for MATLAB</a></li>
<li><a href="http://sourceforge.net/projects/piqle/" rel="nofollow">PIQLE</a> - Platform Implementing Q-Learning and other RL algorithms</li>
<li><a href="https://code.google.com/p/beliefbox/" rel="nofollow">BeliefBox</a> - Bayesian reinforcement learning library and toolkit</li>
<li><a href="https://github.com/nivwusquorum/tensorflow-deepq">Deep Q-Learning with Tensor Flow</a> - A deep Q learning demonstration using Google Tensorflow</li>
<li><a href="https://github.com/Kaixhin/Atari">Atari</a> - Deep Q-networks and asynchronous agents in Torch</li>
<li><a href="https://github.com/yandexdataschool/AgentNet">AgentNet</a> - A python library for deep reinforcement learning and custom recurrent networks using Theano+Lasagne.</li>
<li><a href="https://github.com/rlcode/reinforcement-learning">Reinforcement Learning Examples by RLCode</a> - A Collection of minimal and clean reinforcement learning examples</li>
<li><a href="https://github.com/ShangtongZhang/DeepRL">PyTorch Deep RL</a> - Popular deep RL algorithm implementations with PyTorch</li>
<li><a href="https://github.com/resibots/blackdrops">Black-DROPS</a> - Modular and generic code for the model-based policy search Black-DROPS algorithm (IROS 2017 paper) and easy integration with the <a href="http://dartsim.github.io/" rel="nofollow">DART</a> simulator</li>
</ul>
<h2><a href="#theory" aria-hidden="true" class="anchor" id="user-content-theory"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Theory</h2>
<h3><a href="#lectures" aria-hidden="true" class="anchor" id="user-content-lectures"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Lectures</h3>
<ul>
<li>[UCL] <a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html" rel="nofollow">COMPM050/COMPGI13 Reinforcement Learning</a> by David Silver</li>
<li>[UC Berkeley] CS188 Artificial Intelligence by Pieter Abbeel
<ul>
<li><a href="https://www.youtube.com/watch?v=i0o-ui1N35U" rel="nofollow">Lecture 8: Markov Decision Processes 1</a></li>
<li><a href="https://www.youtube.com/watch?v=Csiiv6WGzKM" rel="nofollow">Lecture 9: Markov Decision Processes 2</a></li>
<li><a href="https://www.youtube.com/watch?v=ifma8G7LegE" rel="nofollow">Lecture 10: Reinforcement Learning 1</a></li>
<li><a href="https://www.youtube.com/watch?v=Si1_YTw960c" rel="nofollow">Lecture 11: Reinforcement Learning 2</a></li>
</ul>
</li>
<li>[Udacity (Georgia Tech.)] <a href="https://classroom.udacity.com/courses/ud600" rel="nofollow">CS7642 Reinforcement Learning</a></li>
<li>[Stanford] <a href="https://www.youtube.com/watch?v=RtxI449ZjSc&amp;feature=relmfu" rel="nofollow">CS229 Machine Learning - Lecture 16: Reinforcement Learning</a> by Andrew Ng</li>
<li>[UC Berkeley] <a href="https://sites.google.com/view/deep-rl-bootcamp/lectures" rel="nofollow">Deep RL Bootcamp</a></li>
<li>[UC Berkeley] <a href="http://rll.berkeley.edu/deeprlcourse/" rel="nofollow">CS294 Deep Reinforcement Learning</a> by John Schulman and Pieter Abbeel</li>
<li>[CMU] <a href="https://katefvision.github.io/" rel="nofollow">10703: Deep Reinforcement Learning and Control, Spring 2017</a></li>
<li>[MIT] <a href="http://selfdrivingcars.mit.edu/" rel="nofollow">6.S094: Deep Learning for Self-Driving Cars</a>
<ul>
<li><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&amp;list=PLrAXtmErZgOeiKm4sgNOknGvNjby9efdf" rel="nofollow">Lecture 2: Deep Reinforcement Learning for Motion Planning</a></li>
</ul>
</li>
</ul>
<h3><a href="#books" aria-hidden="true" class="anchor" id="user-content-books"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Books</h3>
<ul>
<li>Richard Sutton and Andrew Barto, Reinforcement Learning: An Introduction (1st Edition, 1998) <a href="http://incompleteideas.net/book/ebook/the-book.html" rel="nofollow">[Book]</a> <a href="http://incompleteideas.net/book/code/code.html" rel="nofollow">[Code]</a></li>
<li>Richard Sutton and Andrew Barto, Reinforcement Learning: An Introduction (2nd Edition, in progress, 2018) <a href="http://incompleteideas.net/book/bookdraft2018jan1.pdf" rel="nofollow">[Book]</a> <a href="https://github.com/ShangtongZhang/reinforcement-learning-an-introduction">[Code]</a></li>
<li>Csaba Szepesvari, Algorithms for Reinforcement Learning <a href="http://www.ualberta.ca/~szepesva/papers/RLAlgsInMDPs.pdf" rel="nofollow">[Book]</a></li>
<li>David Poole and Alan Mackworth, Artificial Intelligence: Foundations of Computational Agents <a href="http://artint.info/html/ArtInt_262.html" rel="nofollow">[Book Chapter]</a></li>
<li>Dimitri P. Bertsekas and John N. Tsitsiklis, Neuro-Dynamic Programming <a href="http://www.amazon.com/Neuro-Dynamic-Programming-Optimization-Neural-Computation/dp/1886529108/ref=sr_1_3?s=books&amp;ie=UTF8&amp;qid=1442461075&amp;sr=1-3&amp;refinements=p_27%3AJohn+N.+Tsitsiklis+Dimitri+P.+Bertsekas" rel="nofollow">[Book (Amazon)]</a> <a href="http://www.mit.edu/~dimitrib/NDP_Encycl.pdf" rel="nofollow">[Summary]</a></li>
<li>Mykel J. Kochenderfer, Decision Making Under Uncertainty: Theory and Application <a href="http://www.amazon.com/Decision-Making-Under-Uncertainty-Application/dp/0262029251/ref=sr_1_1?ie=UTF8&amp;qid=1441126550&amp;sr=8-1&amp;keywords=kochenderfer&amp;pebp=1441126551594&amp;perid=1Y6RG2EGRD26659CJHH9" rel="nofollow">[Book (Amazon)]</a></li>
</ul>
<h3><a href="#surveys" aria-hidden="true" class="anchor" id="user-content-surveys"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Surveys</h3>
<ul>
<li>Leslie Pack Kaelbling, Michael L. Littman, Andrew W. Moore, Reinforcement Learning: A Survey, JAIR, 1996. <a href="https://www.jair.org/media/301/live-301-1562-jair.pdf" rel="nofollow">[Paper]</a></li>
<li>S. S. Keerthi and B. Ravindran, A Tutorial Survey of Reinforcement Learning, Sadhana, 1994. <a href="http://www.cse.iitm.ac.in/~ravi/papers/keerthi.rl-survey.pdf" rel="nofollow">[Paper]</a></li>
<li>Matthew E. Taylor, Peter Stone, Transfer Learning for Reinforcement Learning Domains: A Survey, JMLR, 2009. <a href="http://machinelearning.wustl.edu/mlpapers/paper_files/jmlr10_taylor09a.pdf" rel="nofollow">[Paper]</a></li>
<li>Jens Kober, J. Andrew Bagnell, Jan Peters, Reinforcement Learning in Robotics, A Survey, IJRR, 2013. <a href="http://www.ias.tu-darmstadt.de/uploads/Publications/Kober_IJRR_2013.pdf" rel="nofollow">[Paper]</a></li>
<li>Michael L. Littman, "Reinforcement learning improves behaviour from evaluative feedback." Nature 521.7553 (2015): 445-451. <a href="http://www.nature.com/nature/journal/v521/n7553/full/nature14540.html" rel="nofollow">[Paper]</a></li>
<li>Marc P. Deisenroth, Gerhard Neumann, Jan Peter, A Survey on Policy Search for Robotics, Foundations and Trends in Robotics, 2014. <a href="https://spiral.imperial.ac.uk:8443/bitstream/10044/1/12051/7/fnt_corrected_2014-8-22.pdf" rel="nofollow">[Book]</a></li>
</ul>
<h3><a href="#papers--thesis" aria-hidden="true" class="anchor" id="user-content-papers--thesis"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Papers / Thesis</h3>
<p>Foundational Papers</p>
<ul>
<li>Marvin Minsky, Steps toward Artificial Intelligence, Proceedings of the IRE, 1961. <a href="http://staffweb.worc.ac.uk/DrC/Courses 2010-11/Comp 3104/Tutor Inputs/Session 9 Prep/Reading material/Minsky60steps.pdf" rel="nofollow">[Paper]</a> (discusses issues in RL such as the "credit assignment problem")</li>
<li>Ian H. Witten, An Adaptive Optimal Controller for Discrete-Time Markov Environments, Information and Control, 1977. <a href="http://www.cs.waikato.ac.nz/~ihw/papers/77-IHW-AdaptiveController.pdf" rel="nofollow">[Paper]</a> (earliest publication on temporal-difference (TD) learning rule)</li>
</ul>
<p>Methods</p>
<ul>
<li>Dynamic Programming (DP):
<ul>
<li>Christopher J. C. H. Watkins, Learning from Delayed Rewards, Ph.D. Thesis, Cambridge University, 1989. <a href="https://www.cs.rhul.ac.uk/home/chrisw/new_thesis.pdf" rel="nofollow">[Thesis]</a></li>
</ul>
</li>
<li>Monte Carlo:
<ul>
<li>Andrew Barto, Michael Duff, Monte Carlo Inversion and Reinforcement Learning, NIPS, 1994. <a href="http://papers.nips.cc/paper/865-monte-carlo-matrix-inversion-and-reinforcement-learning.pdf" rel="nofollow">[Paper]</a></li>
<li>Satinder P. Singh, Richard S. Sutton, Reinforcement Learning with Replacing Eligibility Traces, Machine Learning, 1996. <a href="http://www-all.cs.umass.edu/pubs/1995_96/singh_s_ML96.pdf" rel="nofollow">[Paper]</a></li>
</ul>
</li>
<li>Temporal-Difference:
<ul>
<li>Richard S. Sutton, Learning to predict by the methods of temporal differences. Machine Learning 3: 9-44, 1988. <a href="http://webdocs.cs.ualberta.ca/~sutton/papers/sutton-88-with-erratum.pdf" rel="nofollow">[Paper]</a></li>
</ul>
</li>
<li>Q-Learning (Off-policy TD algorithm):
<ul>
<li>Chris Watkins, Learning from Delayed Rewards, Cambridge, 1989. <a href="http://www.cs.rhul.ac.uk/home/chrisw/thesis.html" rel="nofollow">[Thesis]</a></li>
</ul>
</li>
<li>Sarsa (On-policy TD algorithm):
<ul>
<li>G.A. Rummery, M. Niranjan, On-line Q-learning using connectionist systems, Technical Report, Cambridge Univ., 1994. <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=3&amp;ved=0CDIQFjACahUKEwj2lMm5wZDIAhUHkg0KHa6kAVM&amp;url=ftp%3A%2F%2Fmi.eng.cam.ac.uk%2Fpub%2Freports%2Fauto-pdf%2Frummery_tr166.pdf&amp;usg=AFQjCNHz6IrgcaaO5lzC7t8oEIBY9epozg&amp;sig2=sa-emPme1m5Jav7YmaXsNQ&amp;cad=rja" rel="nofollow">[Report]</a></li>
<li>Richard S. Sutton, Generalization in Reinforcement Learning: Successful examples using sparse coding, NIPS, 1996. <a href="http://webdocs.cs.ualberta.ca/~sutton/papers/sutton-96.pdf" rel="nofollow">[Paper]</a></li>
</ul>
</li>
<li>R-Learning (learning of relative values)
<ul>
<li>Andrew Schwartz, A Reinforcement Learning Method for Maximizing Undiscounted Rewards, ICML, 1993. <a href="https://scholar.google.com/scholar?q=reinforcement+learning+method+for+maximizing+undiscounted+rewards&amp;hl=en&amp;as_sdt=0&amp;as_vis=1&amp;oi=scholart&amp;sa=X&amp;ved=0CBsQgQMwAGoVChMIho6p_MOQyAIVwh0eCh3XWAwM" rel="nofollow">[Paper-Google Scholar]</a></li>
</ul>
</li>
<li>Function Approximation methods (Least-Square Temporal Difference, Least-Square Policy Iteration)
<ul>
<li>Steven J. Bradtke, Andrew G. Barto, Linear Least-Squares Algorithms for Temporal Difference Learning, Machine Learning, 1996. <a href="http://www-anw.cs.umass.edu/pubs/1995_96/bradtke_b_ML96.pdf" rel="nofollow">[Paper]</a></li>
<li>Michail G. Lagoudakis, Ronald Parr, Model-Free Least Squares Policy Iteration, NIPS, 2001. <a href="http://www.cs.duke.edu/research/AI/LSPI/nips01.pdf" rel="nofollow">[Paper]</a> <a href="http://www.cs.duke.edu/research/AI/LSPI/" rel="nofollow">[Code]</a></li>
</ul>
</li>
<li>Policy Search / Policy Gradient
<ul>
<li>Richard Sutton, David McAllester, Satinder Singh, Yishay Mansour, Policy Gradient Methods for Reinforcement Learning with Function Approximation, NIPS, 1999. <a href="http://papers.nips.cc/paper/1713-policy-gradient-methods-for-reinforcement-learning-with-function-approximation.pdf" rel="nofollow">[Paper]</a></li>
<li>Jan Peters, Sethu Vijayakumar, Stefan Schaal, Natural Actor-Critic, ECML, 2005. <a href="https://homes.cs.washington.edu/~todorov/courses/amath579/reading/NaturalActorCritic.pdf" rel="nofollow">[Paper]</a></li>
<li>Jens Kober, Jan Peters, Policy Search for Motor Primitives in Robotics, NIPS, 2009. <a href="http://papers.nips.cc/paper/3545-policy-search-for-motor-primitives-in-robotics.pdf" rel="nofollow">[Paper]</a></li>
<li>Jan Peters, Katharina Mulling, Yasemin Altun, Relative Entropy Policy Search, AAAI, 2010. <a href="http://www.kyb.tue.mpg.de/fileadmin/user_upload/files/publications/attachments/AAAI-2010-Peters_6439%5b0%5d.pdf" rel="nofollow">[Paper]</a></li>
<li>Freek Stulp, Olivier Sigaud, Path Integral Policy Improvement with Covariance Matrix Adaptation, ICML, 2012. <a href="http://arxiv.org/pdf/1206.4621v1.pdf" rel="nofollow">[Paper]</a></li>
<li>Nate Kohl, Peter Stone, Policy Gradient Reinforcement Learning for Fast Quadrupedal Locomotion, ICRA, 2004. <a href="http://www.cs.utexas.edu/~pstone/Papers/bib2html-links/icra04.pdf" rel="nofollow">[Paper]</a></li>
<li>Marc Deisenroth, Carl Rasmussen, PILCO: A Model-Based and Data-Efficient Approach to Policy Search, ICML, 2011. <a href="http://mlg.eng.cam.ac.uk/pub/pdf/DeiRas11.pdf" rel="nofollow">[Paper]</a></li>
<li>Scott Kuindersma, Roderic Grupen, Andrew Barto, Learning Dynamic Arm Motions for Postural Recovery, Humanoids, 2011. <a href="http://www-all.cs.umass.edu/pubs/2011/kuindersma_g_b_11.pdf" rel="nofollow">[Paper]</a></li>
<li>Konstantinos Chatzilygeroudis, Roberto Rama, Rituraj Kaushik, Dorian Goepp, Vassilis Vassiliades, Jean-Baptiste Mouret, Black-Box Data-efficient Policy Search for Robotics, IROS, 2017. [<a href="https://arxiv.org/abs/1703.07261" rel="nofollow">Paper</a>]</li>
</ul>
</li>
<li>Hierarchical RL
<ul>
<li>Richard Sutton, Doina Precup, Satinder Singh, Between MDPs and Semi-MDPs: A Framework for Temporal Abstraction in Reinforcement Learning, Artificial Intelligence, 1999. <a href="https://webdocs.cs.ualberta.ca/~sutton/papers/SPS-aij.pdf" rel="nofollow">[Paper]</a></li>
<li>George Konidaris, Andrew Barto, Building Portable Options: Skill Transfer in Reinforcement Learning, IJCAI, 2007. <a href="http://www-anw.cs.umass.edu/pubs/2007/konidaris_b_IJCAI07.pdf" rel="nofollow">[Paper]</a></li>
</ul>
</li>
<li>Deep Learning + Reinforcement Learning (A sample of recent works on DL+RL)
<ul>
<li>V. Mnih, et. al., Human-level Control through Deep Reinforcement Learning, Nature, 2015. <a href="http://www.readcube.com/articles/10.1038%2Fnature14236?shared_access_token=Lo_2hFdW4MuqEcF3CVBZm9RgN0jAjWel9jnR3ZoTv0P5kedCCNjz3FJ2FhQCgXkApOr3ZSsJAldp-tw3IWgTseRnLpAc9xQq-vTA2Z5Ji9lg16_WvCy4SaOgpK5XXA6ecqo8d8J7l4EJsdjwai53GqKt-7JuioG0r3iV67MQIro74l6IxvmcVNKBgOwiMGi8U0izJStLpmQp6Vmi_8Lw_A%3D%3D" rel="nofollow">[Paper]</a></li>
<li>Xiaoxiao Guo, Satinder Singh, Honglak Lee, Richard Lewis, Xiaoshi Wang, Deep Learning for Real-Time Atari Game Play Using Offline Monte-Carlo Tree Search Planning, NIPS, 2014. <a href="http://papers.nips.cc/paper/5421-deep-learning-for-real-time-atari-game-play-using-offline-monte-carlo-tree-search-planning.pdf" rel="nofollow">[Paper]</a></li>
<li>Sergey Levine, Chelsea Finn, Trevor Darrel, Pieter Abbeel, End-to-End Training of Deep Visuomotor Policies. ArXiv, 16 Oct 2015. <a href="http://arxiv.org/pdf/1504.00702v3.pdf" rel="nofollow">[ArXiv]</a></li>
<li>Tom Schaul, John Quan, Ioannis Antonoglou, David Silver, Prioritized Experience Replay, ArXiv, 18 Nov 2015. <a href="http://arxiv.org/pdf/1511.05952v2.pdf" rel="nofollow">[ArXiv]</a></li>
<li>Hado van Hasselt, Arthur Guez, David Silver, Deep Reinforcement Learning with Double Q-Learning, ArXiv, 22 Sep 2015. <a href="http://arxiv.org/abs/1509.06461" rel="nofollow">[ArXiv]</a></li>
<li>Volodymyr Mnih, Adrià Puigdomènech Badia, Mehdi Mirza, Alex Graves, Timothy P. Lillicrap, Tim Harley, David Silver, Koray Kavukcuoglu, Asynchronous Methods for Deep Reinforcement Learning, ArXiv, 4 Feb 2016. <a href="https://arxiv.org/abs/1602.01783" rel="nofollow">[ArXiv]</a></li>
</ul>
</li>
</ul>
<h2><a href="#applications" aria-hidden="true" class="anchor" id="user-content-applications"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Applications</h2>
<h3><a href="#game-playing" aria-hidden="true" class="anchor" id="user-content-game-playing"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Game Playing</h3>
<p>Traditional Games</p>
<ul>
<li>Backgammon - "TD-Gammon" game play using TD(λ) (Tesauro, ACM 1995) <a href="http://www.bkgm.com/articles/tesauro/tdl.html" rel="nofollow">[Paper]</a></li>
<li>Chess - "KnightCap" program using TD(λ) (Baxter, arXiv 1999) <a href="http://arxiv.org/pdf/cs/9901002v1.pdf" rel="nofollow">[arXiv]</a></li>
<li>Chess - Giraffe: Using deep reinforcement learning to play chess (Lai, arXiv 2015) <a href="http://arxiv.org/pdf/1509.01549v2.pdf" rel="nofollow">[arXiv]</a></li>
</ul>
<p>Computer Games</p>
<ul>
<li>Human-level Control through Deep Reinforcement Learning (Mnih, Nature 2015) <a href="http://www.readcube.com/articles/10.1038%2Fnature14236?shared_access_token=Lo_2hFdW4MuqEcF3CVBZm9RgN0jAjWel9jnR3ZoTv0P5kedCCNjz3FJ2FhQCgXkApOr3ZSsJAldp-tw3IWgTseRnLpAc9xQq-vTA2Z5Ji9lg16_WvCy4SaOgpK5XXA6ecqo8d8J7l4EJsdjwai53GqKt-7JuioG0r3iV67MQIro74l6IxvmcVNKBgOwiMGi8U0izJStLpmQp6Vmi_8Lw_A%3D%3D" rel="nofollow">[Paper]</a> <a href="https://sites.google.com/a/deepmind.com/dqn/" rel="nofollow">[Code]</a> <a href="https://www.youtube.com/watch?v=iqXKQf2BOSE" rel="nofollow">[Video]</a></li>
<li><a href="https://github.com/SarvagyaVaish/FlappyBirdRL">Flappy Bird Reinforcement Learning</a> <a href="https://www.youtube.com/watch?v=xM62SpKAZHU" rel="nofollow">[Video]</a></li>
<li>MarI/O - learning to play Mario with evolutionary reinforcement learning using artificial neural networks (Stanley, Evolutionary Computation 2002) <a href="http://nn.cs.utexas.edu/downloads/papers/stanley.ec02.pdf" rel="nofollow">[Paper]</a> <a href="https://www.youtube.com/watch?v=qv6UVOQ0F44" rel="nofollow">[Video]</a></li>
</ul>
<h3><a href="#robotics" aria-hidden="true" class="anchor" id="user-content-robotics"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Robotics</h3>
<ul>
<li>Policy Gradient Reinforcement Learning for Fast Quadrupedal Locomotion (Kohl, ICRA 2004) <a href="http://www.cs.utexas.edu/~pstone/Papers/bib2html-links/icra04.pdf" rel="nofollow">[Paper]</a></li>
<li>Robot Motor SKill Coordination with EM-based Reinforcement Learning (Kormushev, IROS 2010) <a href="http://kormushev.com/papers/Kormushev-IROS2010.pdf" rel="nofollow">[Paper]</a> <a href="https://www.youtube.com/watch?v=W_gxLKSsSIE" rel="nofollow">[Video]</a></li>
<li>Generalized Model Learning for Reinforcement Learning on a Humanoid Robot (Hester, ICRA 2010) <a href="https://ccc.inaoep.mx/~mdprl/documentos/Hester_2010.pdf" rel="nofollow">[Paper]</a> <a href="https://www.youtube.com/watch?v=mRpX9DFCdwI&amp;list=PL5nBAYUyJTrM48dViibyi68urttMlUv7e&amp;index=12" rel="nofollow">[Video]</a></li>
<li>Autonomous Skill Acquisition on a Mobile Manipulator (Konidaris, AAAI 2011) <a href="http://lis.csail.mit.edu/pubs/konidaris-aaai11b.pdf" rel="nofollow">[Paper]</a> <a href="https://www.youtube.com/watch?v=yUICAkSQTZY" rel="nofollow">[Video]</a></li>
<li>PILCO: A Model-Based and Data-Efficient Approach to Policy Search (Deisenroth, ICML 2011) <a href="http://mlg.eng.cam.ac.uk/pub/pdf/DeiRas11.pdf" rel="nofollow">[Paper]</a></li>
<li>Incremental Semantically Grounded Learning from Demonstration (Niekum, RSS 2013) <a href="http://people.cs.umass.edu/~sniekum/pubs/NiekumRSS2013.pdf" rel="nofollow">[Paper]</a></li>
<li>Efficient Reinforcement Learning for Robots using Informative Simulated Priors (Cutler, ICRA 2015) <a href="http://markjcutler.com/papers/Cutler15_ICRA.pdf" rel="nofollow">[Paper]</a> <a href="https://www.youtube.com/watch?v=kKClFx6l1HY" rel="nofollow">[Video]</a></li>
<li>Robots that can adapt like animals (Cully, Nature 2015) [<a href="https://arxiv.org/abs/1407.3501" rel="nofollow">Paper</a>] [<a href="https://www.youtube.com/watch?v=T-c17RKh3uE" rel="nofollow">Video</a>] [<a href="https://github.com/resibots/cully_2015_nature">Code</a>]</li>
<li>Black-Box Data-efficient Policy Search for Robotics (Chatzilygeroudis, IROS 2017) [<a href="https://arxiv.org/abs/1703.07261" rel="nofollow">Paper</a>] [<a href="https://www.youtube.com/watch?v=kTEyYiIFGPM" rel="nofollow">Video</a>] [<a href="https://github.com/resibots/blackdrops">Code</a>]</li>
</ul>
<h3><a href="#control" aria-hidden="true" class="anchor" id="user-content-control"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Control</h3>
<ul>
<li>An Application of Reinforcement Learning to Aerobatic Helicopter Flight (Abbeel, NIPS 2006) <a href="http://heli.stanford.edu/papers/nips06-aerobatichelicopter.pdf" rel="nofollow">[Paper]</a> <a href="https://www.youtube.com/watch?v=VCdxqn0fcnE" rel="nofollow">[Video]</a></li>
<li>Autonomous helicopter control using Reinforcement Learning Policy Search Methods (Bagnell, ICRA 2001) <a href="http://repository.cmu.edu/cgi/viewcontent.cgi?article=1082&amp;context=robotics" rel="nofollow">[Paper]</a></li>
</ul>
<h3><a href="#operations-research" aria-hidden="true" class="anchor" id="user-content-operations-research"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Operations Research</h3>
<ul>
<li>Scaling Average-reward Reinforcement Learning for Product Delivery (Proper, AAAI 2004) <a href="http://web.engr.oregonstate.edu/~proper/AAAI04SProper.pdf" rel="nofollow">[Paper]</a></li>
<li>Cross Channel Optimized Marketing by Reinforcement Learning (Abe, KDD 2004) <a href="http://www.research.ibm.com/people/n/nabe/kdd04AVAS.pdf" rel="nofollow">[Paper]</a></li>
</ul>
<h3><a href="#human-computer-interaction" aria-hidden="true" class="anchor" id="user-content-human-computer-interaction"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Human Computer Interaction</h3>
<ul>
<li>Optimizing Dialogue Management with Reinforcement Learning: Experiments with the NJFun System (Singh, JAIR 2002) <a href="http://web.eecs.umich.edu/~baveja/Papers/RLDSjair.pdf" rel="nofollow">[Paper]</a></li>
</ul>
<h2><a href="#tutorials--websites" aria-hidden="true" class="anchor" id="user-content-tutorials--websites"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Tutorials / Websites</h2>
<ul>
<li>Mance Harmon and Stephanie Harmon, <a href="http://old.nbu.bg/cogs/events/2000/Readings/Petrov/rltutorial.pdf" rel="nofollow">Reinforcement Learning: A Tutorial</a></li>
<li>C. Igel, M.A. Riedmiller, et al., Reinforcement Learning in a Nutshell, ESANN, 2007. <a href="http://image.diku.dk/igel/paper/RLiaN.pdf" rel="nofollow">[Paper]</a></li>
<li>UNSW - <a href="http://www.cse.unsw.edu.au/~cs9417ml/RL1/index.html" rel="nofollow">Reinforcement Learning</a></li>
<li><a href="http://www.cse.unsw.edu.au/~cs9417ml/RL1/introduction.html" rel="nofollow">Introduction</a></li>
<li><a href="http://www.cse.unsw.edu.au/~cs9417ml/RL1/tdlearning.html" rel="nofollow">TD-Learning</a></li>
<li><a href="http://www.cse.unsw.edu.au/~cs9417ml/RL1/algorithms.html" rel="nofollow">Q-Learning and SARSA</a></li>
<li><a href="http://www.cse.unsw.edu.au/~cs9417ml/RL1/applet.html" rel="nofollow">Applet for "Cat and Mouse" Game</a></li>
<li><a href="http://wiki.ros.org/reinforcement_learning/Tutorials/Reinforcement Learning Tutorial" rel="nofollow">ROS Reinforcement Learning Tutorial</a></li>
<li><a href="http://cs.brown.edu/research/ai/pomdp/tutorial/index.html" rel="nofollow">POMDP for Dummies</a></li>
<li>Scholarpedia articles on:</li>
<li><a href="http://www.scholarpedia.org/article/Reinforcement_learning" rel="nofollow">Reinforcement Learning</a></li>
<li><a href="http://www.scholarpedia.org/article/Temporal_difference_learning" rel="nofollow">Temporal Difference Learning</a></li>
<li>Repository with useful <a href="http://busoniu.net/repository.php" rel="nofollow">MATLAB Software, presentations, and demo videos</a></li>
<li><a href="http://liinwww.ira.uka.de/bibliography/Neural/reinforcement.learning.html" rel="nofollow">Bibliography on Reinforcement Learning</a></li>
<li>UC Berkeley - CS 294: Deep Reinforcement Learning, Fall 2015 (John Schulman, Pieter Abbeel) <a href="http://rll.berkeley.edu/deeprlcourse/" rel="nofollow">[Class Website]</a></li>
<li><a href="https://studywolf.wordpress.com/2012/11/25/reinforcement-learning-q-learning-and-exploration/" rel="nofollow">Blog posts on Reinforcement Learning, Parts 1-4</a> by Travis DeWolf</li>
<li><a href="http://www.arcadelearningenvironment.org/" rel="nofollow">The Arcade Learning Environment</a> - Atari 2600 games environment for developing AI agents</li>
<li><a href="http://karpathy.github.io/2016/05/31/rl/" rel="nofollow">Deep Reinforcement Learning: Pong from Pixels</a> by Andrej Karpathy</li>
<li><a href="https://www.nervanasys.com/demystifying-deep-reinforcement-learning/" rel="nofollow">Demystifying Deep Reinforcement Learning</a></li>
<li><a href="https://jaromiru.com/2016/09/27/lets-make-a-dqn-theory/" rel="nofollow">Let’s make a DQN</a></li>
<li><a href="https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0#.78km20i8r" rel="nofollow">Simple Reinforcement Learning with Tensorflow, Parts 0-8</a> by Arthur Juliani</li>
<li><a href="https://github.com/yandexdataschool/Practical_RL">Practical_RL</a> - github-based course in reinforcement learning in the wild (lectures, coding labs, projects)</li>
</ul>
<h2><a href="#online-demos" aria-hidden="true" class="anchor" id="user-content-online-demos"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Online Demos</h2>
<ul>
<li><a href="http://www.dcsc.tudelft.nl/~robotics/media.html" rel="nofollow">Real-world demonstrations of Reinforcement Learning</a></li>
<li><a href="http://cs.stanford.edu/people/karpathy/convnetjs/demo/rldemo.html" rel="nofollow">Deep Q-Learning Demo</a> - A deep Q learning demonstration using ConvNetJS</li>
<li><a href="https://github.com/nivwusquorum/tensorflow-deepq">Deep Q-Learning with Tensor Flow</a> - A deep Q learning demonstration using Google Tensorflow</li>
<li><a href="http://cs.stanford.edu/people/karpathy/reinforcejs/" rel="nofollow">Reinforcement Learning Demo</a> - A reinforcement learning demo using reinforcejs by Andrej Karpathy</li>
</ul>
<h2><a href="#open-source-reinforcement-learning-platforms" aria-hidden="true" class="anchor" id="user-content-open-source-reinforcement-learning-platforms"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Open Source Reinforcement Learning Platforms</h2>
<ul>
<li><a href="https://github.com/openai/gym">OpenAI gym</a> - A toolkit for developing and comparing reinforcement learning algorithms</li>
<li><a href="https://github.com/openai/universe">OpenAI universe</a> - A software platform for measuring and training an AI's general intelligence across the world's supply of games, websites and other applications</li>
<li><a href="https://github.com/deepmind/lab">DeepMind Lab</a> - A customisable 3D platform for agent-based AI research</li>
<li><a href="https://github.com/Microsoft/malmo">Project Malmo</a> - A platform for Artificial Intelligence experimentation and research built on top of Minecraft by Microsoft</li>
<li><a href="https://github.com/Marqt/ViZDoom">ViZDoom</a> - Doom-based AI research platform for reinforcement learning from raw visual information</li>
<li><a href="https://github.com/nadavbh12/Retro-Learning-Environment">Retro Learning Environment</a> - An AI platform for reinforcement learning based on video game emulators. Currently supports SNES and Sega Genesis. Compatible with OpenAI gym.</li>
<li><a href="https://github.com/twitter/torch-twrl">torch-twrl</a> - A package that enables reinforcement learning in Torch by Twitter</li>
<li><a href="https://github.com/facebook/UETorch">UETorch</a> - A Torch plugin for Unreal Engine 4 by Facebook</li>
<li><a href="https://github.com/TorchCraft/TorchCraft">TorchCraft</a> - Connecting Torch to StarCraft</li>
<li><a href="https://github.com/openai/rllab">rllab</a> - A framework for developing and evaluating reinforcement learning algorithms, fully compatible with OpenAI Gym</li>
<li><a href="https://github.com/reinforceio/tensorforce">TensorForce</a> - Practical deep reinforcement learning on TensorFlow with Gitter support and OpenAI Gym/Universe/DeepMind Lab integration.</li>
<li><a href="https://github.com/kengz/openai_lab">OpenAI lab</a> - An experimentation system for Reinforcement Learning using OpenAI Gym, Tensorflow, and Keras.</li>
<li><a href="https://github.com/matthiasplappert/keras-rl">keras-rl</a> - State-of-the art deep reinforcement learning algorithms in Keras designed for compatibility with OpenAI.</li>
<li><a href="http://burlap.cs.brown.edu/" rel="nofollow">BURLAP</a> - Brown-UMBC Reinforcement Learning and Planning, a library written in Java</li>
<li><a href="https://github.com/geek-ai/MAgent">MAgent</a> - A Platform for Many-agent Reinforcement Learning.</li>
<li><a href="http://ray.readthedocs.io/en/latest/rllib.html" rel="nofollow">Ray RLlib</a> - Ray RLlib is a reinforcement learning library that aims to provide both performance and composability.</li>
</ul>
</article>
  </div>


  </div>
  <div class="modal-backdrop js-touch-events"></div>
</div>

    </div>
  </div>

  </div>

      
<div class="footer container-lg px-3" role="contentinfo">
  <div class="position-relative d-flex flex-justify-between pt-6 pb-2 mt-6 f6 text-gray border-top border-gray-light ">
    <ul class="list-style-none d-flex flex-wrap ">
      <li class="mr-3">&copy; 2018 <span title="0.28789s from unicorn-3810275544-sf71p">GitHub</span>, Inc.</li>
        <li class="mr-3"><a data-ga-click="Footer, go to terms, text:terms" href="https://github.com/site/terms">Terms</a></li>
        <li class="mr-3"><a data-ga-click="Footer, go to privacy, text:privacy" href="https://github.com/site/privacy">Privacy</a></li>
        <li class="mr-3"><a href="https://help.github.com/articles/github-security/" data-ga-click="Footer, go to security, text:security">Security</a></li>
        <li class="mr-3"><a href="https://status.github.com/" data-ga-click="Footer, go to status, text:status">Status</a></li>
        <li><a data-ga-click="Footer, go to help, text:help" href="https://help.github.com/">Help</a></li>
    </ul>

    <a aria-label="Homepage" title="GitHub" class="footer-octicon" href="https://github.com/">
      <svg height="24" class="octicon octicon-mark-github" viewBox="0 0 16 16" version="1.1" width="24" aria-hidden="true"><path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z"/></svg>
</a>
   <ul class="list-style-none d-flex flex-wrap ">
        <li class="mr-3"><a data-ga-click="Footer, go to contact, text:contact" href="https://github.com/contact">Contact GitHub</a></li>
      <li class="mr-3"><a href="https://developer.github.com/" data-ga-click="Footer, go to api, text:api">API</a></li>
      <li class="mr-3"><a href="https://training.github.com/" data-ga-click="Footer, go to training, text:training">Training</a></li>
      <li class="mr-3"><a href="https://shop.github.com/" data-ga-click="Footer, go to shop, text:shop">Shop</a></li>
        <li class="mr-3"><a data-ga-click="Footer, go to blog, text:blog" href="https://github.com/blog">Blog</a></li>
        <li><a data-ga-click="Footer, go to about, text:about" href="https://github.com/about">About</a></li>

    </ul>
  </div>
  <div class="d-flex flex-justify-center pb-6">
    <span class="f6 text-gray-light"></span>
  </div>
</div>



  <div id="ajax-error-message" class="ajax-error-message flash flash-error">
    <svg class="octicon octicon-alert" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8.865 1.52c-.18-.31-.51-.5-.87-.5s-.69.19-.87.5L.275 13.5c-.18.31-.18.69 0 1 .19.31.52.5.87.5h13.7c.36 0 .69-.19.86-.5.17-.31.18-.69.01-1L8.865 1.52zM8.995 13h-2v-2h2v2zm0-3h-2V6h2v4z"/></svg>
    <button type="button" class="flash-close js-ajax-error-dismiss" aria-label="Dismiss error">
      <svg class="octicon octicon-x" viewBox="0 0 12 16" version="1.1" width="12" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.48 8l3.75 3.75-1.48 1.48L6 9.48l-3.75 3.75-1.48-1.48L4.52 8 .77 4.25l1.48-1.48L6 6.52l3.75-3.75 1.48 1.48z"/></svg>
    </button>
    You can't perform that action at this time.
  </div>


    <script crossorigin="anonymous" type="application/javascript" src="https://assets-cdn.github.com/assets/compat-680e7bbbbe79068a1cb3142329468a6f.js"></script>
    <script crossorigin="anonymous" type="application/javascript" src="https://assets-cdn.github.com/assets/frameworks-4a55ab3fcf005abef1e8b859483f3cce.js"></script>
    
    <script crossorigin="anonymous" async="async" type="application/javascript" src="https://assets-cdn.github.com/assets/github-bb9389ddb48b82c0ab8aac117b804993.js"></script>
    
    
    
    
  <div class="js-stale-session-flash stale-session-flash flash flash-warn flash-banner d-none">
    <svg class="octicon octicon-alert" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8.865 1.52c-.18-.31-.51-.5-.87-.5s-.69.19-.87.5L.275 13.5c-.18.31-.18.69 0 1 .19.31.52.5.87.5h13.7c.36 0 .69-.19.86-.5.17-.31.18-.69.01-1L8.865 1.52zM8.995 13h-2v-2h2v2zm0-3h-2V6h2v4z"/></svg>
    <span class="signed-in-tab-flash">You signed in with another tab or window. <a href="#">Reload</a> to refresh your session.</span>
    <span class="signed-out-tab-flash">You signed out in another tab or window. <a href="#">Reload</a> to refresh your session.</span>
  </div>
  <div class="facebox" id="facebox" style="display:none;">
  <div class="facebox-popup">
    <div class="facebox-content" role="dialog" aria-labelledby="facebox-header" aria-describedby="facebox-description">
    </div>
    <button type="button" class="facebox-close js-facebox-close" aria-label="Close modal">
      <svg class="octicon octicon-x" viewBox="0 0 12 16" version="1.1" width="12" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.48 8l3.75 3.75-1.48 1.48L6 9.48l-3.75 3.75-1.48-1.48L4.52 8 .77 4.25l1.48-1.48L6 6.52l3.75-3.75 1.48 1.48z"/></svg>
    </button>
  </div>
</div>

  <div class="Popover js-hovercard-content position-absolute" style="display: none; outline: none;" tabindex="0">
  <div class="Popover-message Popover-message--bottom-left Popover-message--large Box box-shadow-large" style="width:360px;">
  </div>
</div>

<div id="hovercard-aria-description" class="sr-only">
  Press h to open a hovercard with more details.
</div>


  </body>

<!-- Mirrored from github.com/aikorea/awesome-rl by HTTrack Website Copier/3.x [XR&CO'2014], Tue, 10 Apr 2018 07:05:01 GMT -->
</html>

